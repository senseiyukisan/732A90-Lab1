---
title: "Computational Statistics Lab1"
author: "Yuki Washio and Nicolas Taba"
date: "02/11/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1: Be Careful when comparing

**1.**

- In the first code snippet, the value of $x_1=1/3$ is a infinite decimal number. In the floating point number representation, only a value that is similar to it is stored in the 64bits memory capacity. There is a rounding error called underflow that occurs when we operate on this value.

- In the second code snippet, no rounding error is made. Therefore, the subtraction is correct.

**2.**

One possibility to improve the first code snippet is doing the following:

```{r code snippets}
x1 <- 1 ; x2 <- 1/2
if (isTRUE(all.equal( x1 - x2, 1/2))){
  print("substraction is correct")
}else{
  print("substraction is wrong")
}
```

This works because the **all.equal** method tests for "near equality" between the two quantities instead of exact results up to machine precision.

## Question 2: Derivative

**1.**

Here, we evaluate the derivative of $f(x) = x$ by writing out own R function.

```{r derivative}
epsilon = 10^(-15)

derivative <- function(x){
  stopifnot(is.numeric(x))
  dx <- ((x+epsilon) - x)/(epsilon)
  return(dx)
}

```

**2.**

We now evaluate for $x = 1$ and $x = 100000$

```{r derivative1, echo=TRUE}
x1 = 1
x2 = 100000
derivative(x1)
derivative(x2)
```

**3.**

The true value of the derivative is 1.
For $x = 1$, there is underflow in the calculation as we loose significant digits when dividing.
For $x = 100000$, we have the difference in the nominator that is evaluated to be zero and the division by $\epsilon$, which is small and doesn't get stored properly. We have underflow in this case


## Question 3: Variance

```{r, echo=FALSE}
library(ggplot2)
```

This time, we are asked to write a *myvar* function to calculate the variance based on a  vector given by the exercise. We then generate a vector with 10000 random numbers with mean $10^8$ and variance 1. We then compare our function to the in-built function *var* in R. We plot the dependence of the difference with respect to the length of the vector.

**1. and 2.**

```{r variance, echo = TRUE}
myvar <- function(x){
  stopifnot(is.vector(x),
            is.numeric(x))
  n <- length(x)
  variance <- (1/(n-1))*(sum(x^2) - (1/n)*((sum(x))^2))
  return(variance)
}

vect_x <- rnorm(10000, mean = 10^8, sd = 1)

Y <- c()
for (i in 1:length(vect_x)){
  Y[i] <- myvar(vect_x[1:i]) - var(vect_x[1:i])
}

Y = Y[!is.na(Y)]

```

**3.**

and now we plot the dependence of $Y_i$ on $i$.

```{r variance_plot}
data_Y <- data.frame(values = Y, len = 1:length(Y))
plot_dependence <- ggplot(data = data_Y) +
  geom_point(aes(x = len, y = values)) + 
  xlab("i") +
  ylab("Y_i")

print(plot_dependence)
```

If *myvar* was a good estimate and close to the var function in R, we would expect to see all values of their difference to be equal to 0. This graph shows that the values are concentrated around -1. The subtraction between large elements in the summation may lead to catastrophic cancellation and to overflow in the summation. It is not immediately clear if the summations themselves are conducted properly as we are summing from larger to smaller values. We must find a way to prevent this issue. Summing in reverse order might lead to a better result as small terms could better contribute to the calculation, but it would still be inaccurate.

**4.**

We can improve the calculation of the variance by remembering that the sample variance is $$V[X] = \frac{1}{n-1}\sum_{i=1}^n(X_i - \bar{X})^2$$. This is a good estimate of the variance of a population if the sample is large enough (which is our case). We can thus improve our variance calculation in the following way:

```{r variance_improve}
myvar_improved <- function(x){
  stopifnot(is.vector(x),
            is.numeric(x))
  mu <- mean(x)
  n <- length(x)
  variance_improved <- sum((x - mu)^2)/(n-1)
  return(variance_improved)
}

Y_improved <- c()
for (i in 1:length(vect_x)){
  Y_improved[i] <- myvar_improved(vect_x[1:i]) - var(vect_x[1:i])
}

Y_improved = Y_improved[!is.na(Y_improved)]

data_Y_improved <- data.frame(values = Y_improved, len = 1:length(Y_improved))

plot_dependence_improved <- 
  ggplot(data = data_Y_improved) +
  geom_line(aes(x = len, y = values)) + 
  xlab("i") +
  ylab("Y_i") + 
  ylim(-5,5)

print(plot_dependence_improved)
```

We have obtained better result this time by performing only one summation and comparing the numbers within the summation operation.

## Question 4: Binomial coefficient

**1.**

For all expressions, *R* will throw an error if either $k=0$ (A) or $n-k=0$ (A,B,C) as R will be unable to compute a division by zero.

**2.**

```{r binomial}
# Formulae A
binom_a <- function(n,k){
  stopifnot(is.numeric(n), is.numeric(k))
  coeff_a <- prod(1:n) / (prod(1:k) * prod(1:(n-k)))
  cat("Formulae A:\nn =", n, ", k =", k,
      "\nprod(1:n):", prod(1:n),
      "\nprod(1:k):", prod(1:k),
      "\nprod(1:(n-k)):", prod(1:(n-k)),
      "\n->", n, "choose", k, "=", coeff_a, "\n\n")
  return(coeff_a)
}
# Formulae B
binom_b <- function(n,k){
  stopifnot(is.numeric(n), is.numeric(k))
  coeff_b <- prod((k+1):n) / prod(1:(n-k))
  cat("Formulae B:\nn =", n, ", k =", k,
      "\nprod((k+1):n):", prod((k+1):n),
      "\nprod(1:(n-k)):", prod(1:(n-k)),
      "\n->", n, "choose", k, "=", coeff_b, "\n\n")
  return(coeff_b)
}
# Formulae C
binom_c <- function(n,k){
  stopifnot(is.numeric(n), is.numeric(k))
  coeff_c <- prod(((k+1):n) / (1:(n-k)))
  cat("Formulae C:\nn =", n, ", k =", k,
      "\nprod(((k+1):n) / (1:(n-k))):", prod(((k+1):n) / (1:(n-k))),
      "\n->", n, "choose", k, "=", coeff_c, "\n\n")
  return(coeff_c)
}


n <- c(2, 10, 10^2, 10^4)
k1 <- c(1, 8, 98, 9995)
k2 <- c(0, 1, 2, 4)
```

We define $n=(2, 10, 10^2, 10^4)$, $k_1=(1, 8, 98, 9995)$ and $k_2=(0, 1, 2, 4)$. In the following we will calculate the binomial coefficient for each combination of $n$ and $k_1$ as well as $n$ and $k_2$ using our three *R* expressions. This allows us to determine whether there is overflow for different input parameters for $\binom{n}{k}$. 

```{r binomial2}
for(i in 1:4){
  
  # Small difference between n and k
  binom_a(n[i], k1[i])
  binom_b(n[i], k1[i])
  binom_c(n[i], k1[i])

  # Big difference between n and k
  binom_a(n[i], k2[i])
  binom_b(n[i], k2[i])
  binom_c(n[i], k2[i])
}
```

**3.**

### Formulae A

If either $k=0$ or $n-k=0$, then $denominator=0$ and if $numerator=0$, then $result=NaN$. For every other $numerator>0$ we will get $result=Inf$, because any positive integer or *Inf* divided by *0* will become *Inf*.

If $n>170$, then $n!=Inf$. This behavior is called *overflow*. Off course the same applies for $k>170$, then in the denominator we will get $k!=Inf$. Therefore, if $numerator=Inf$ and $denominator=Inf$ we will get $result=NaN$.

If $n=k$ and $n,k <= 170$, then the right side of the denominator will equal to *0*. Therefore, $denominator=0$ and $result=Inf$. Else if $n=k$ and $n,k > 170$, then $(prod(1:k)=Inf$ and $prod(1:(n-k))=0$. Therefore, $Inf*0=NaN$ and $result=\frac{Inf}{NaN}=NaN$.

### Formulae B

For this implementation *overflow* can be detected if $n-k>170$. This is because when calling $prod((k+1):n)$ with a big *n* and a small *k*, *R* can't handle this calculation and evaluates this expression to *Inf*. The same applies for the the *denominator*, $prod(1:(n-k))$ will evaluate to *Inf*, too. Therefore, $result=NaN$.

If $n-k<170$ and $numerator=Inf$, we get $result=\frac{prod((k+1):n)}{prod(1:(n-k))}=\frac{Inf}{0<denominator<Inf}=Inf$

If $n=k$, then $\frac{prod((k+1):n)}{prod(1:(n-k))}=\frac{Integer}{0}$. Therefore, $result=Inf$

### Formulae C

This formulae delivers the best results for calculating diverse *n* and *k* values. This is because the critical *prod()* function is only called at the end after calculating the *quotient* for $\frac{((k+1):n)}{(1:(n-k))}$.

The only issue that might come up is *underflow* by dividing values from the *numerator-vector* with the according values from the *denominator-vector*. 


